"""
Lightâ€‘weight wrapper for AudioLDMÂ 2 textâ€‘toâ€‘audio generation.

ðŸ“¦  Requirements (oneâ€‘time):
    pip install torch torchaudio audioldm2 --upgrade

The first call will download model weights (~2â€¯GB) to your HF cache.
Everything is kept selfâ€‘contained: the function returns the absolute
path of a 16â€‘bit WAV file saved inside ./data/.
"""

from pathlib import Path
import time
import torchaudio
from audioldm2 import text_to_audio


def _timestamp() -> str:
    return time.strftime("%Y%m%d_%H%M%S")


def generate_audio(prompt: str, duration_s: int) -> str:
    """Generate `duration_s` seconds of audio for `prompt` and return WAV path."""
    if not prompt:
        raise ValueError("Prompt must not be empty")

    # 1. Create output directory ------------------------------------------------
    out_dir = Path("data")
    out_dir.mkdir(exist_ok=True)

    # 2. Call AudioLDM ----------------------------------------------------------
    #    200 inference steps give reasonable quality on 8â€¯GB VRAM â€“ adjust if
    #    you need faster results (e.g. 100).  Sample rate is always 16Â kHz.
    print(f"[AudioLDM] Generating '{prompt}' ({duration_s}s)â€¦")
    audio_tensor, sr = text_to_audio(
        prompt,
        audio_length_in_s=duration_s,
        num_inference_steps=200,
        guidance_scale=3.5,  # tradeâ€‘off between fidelity / creativity
    )

    # 3. Save WAV ---------------------------------------------------------------
    filename = f"tg_{_timestamp()}.wav"
    out_path = out_dir / filename
    torchaudio.save(str(out_path), audio_tensor, sample_rate=sr, bits_per_sample=16)

    print(f"[AudioLDM] Saved â†’ {out_path.resolve()}")
    return str(out_path.resolve())
